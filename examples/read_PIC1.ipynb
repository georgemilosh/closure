{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Simulation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments = ['high_res_bg0', 'high_res_2', 'high_res_bg3', 'high_res_hbg']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import read_pic as rp\n",
    "import os\n",
    "# Fields to read.\n",
    "fields_to_read={\"B\":True,\"B_ext\":False,\"divB\":False,\"E\":True,\"E_ext\":False,\"rho\":True,\"J\":True,\n",
    "                \"P\":True,\"PI\":False,\"Heat_flux\":True,\"N\":False,\"Qrem\":False}\n",
    "# Path of the folder containing the .h5 files to read.\n",
    "files_path=\"../../nn/data/raw_data/\" # \"/users/cpa/francesc/share_dir/SW/data_small/\" #\"/users/cpa/francesc/share_dir/jincai/dat_FF2D07e/\" #=\"/users/cpa/francesc/share_dir/nn/data/raw_data/\"\n",
    "processed_files_path = \"/Users/u0167590/github/closure/data/brecht/processed/intraexp\"\n",
    "experiments = [f.name for f in os.scandir(files_path) if f.is_dir()]\n",
    "print(f\"{experiments = }\")\n",
    "# Below we choose only initial time step just to view spatial distribution of the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filenames = [f'high_res_2/DoubleHarris-Fields_0{time}.h5' for time in range(10000,15000,1000)] + \\\n",
    "    [f'high_res_bg0/DoubleHarris-Fields_0{time}.h5' for time in range(10000,15000,1000)]\n",
    "train = pd.DataFrame({'filenames': filenames})\n",
    "if not os.path.exists(f'{processed_files_path}/train.csv'):\n",
    "    train.to_csv(f'{processed_files_path}/train.csv', index=False)\n",
    "filenames = [f'high_res_2/DoubleHarris-Fields_0{time}.h5' for time in range(15000,18000,1000)] + \\\n",
    "    [f'high_res_bg0/DoubleHarris-Fields_0{time}.h5' for time in range(15000,18000,1000)]\n",
    "val = pd.DataFrame({'filenames': filenames})\n",
    "if not os.path.exists(f'{processed_files_path}/val.csv'):\n",
    "    val.to_csv(f'{processed_files_path}/val.csv', index=False)\n",
    "filenames = [f'high_res_2/DoubleHarris-Fields_0{time}.h5' for time in range(18000,20000,1000)] + \\\n",
    "    [f'high_res_bg0/DoubleHarris-Fields_0{time}.h5' for time in range(18000,20000,1000)]\n",
    "test = pd.DataFrame({'filenames': filenames})\n",
    "if not os.path.exists(f'{processed_files_path}/test.csv'):\n",
    "    test.to_csv(f'{processed_files_path}/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib as imp \n",
    "import numpy as np\n",
    "imp.reload(rp)\n",
    "\n",
    "features, targets = rp.read_features_targets(files_path, filenames, fields_to_read,\n",
    "                                             request_features = ['Bmagn', 'Emagn', ['rho','e'], ['Vmagn','e']], \n",
    "                                  request_targets =[['qx','e']], \n",
    "                                choose_species=['e',None,'e',None],choose_x=[0,384], choose_y=[179,333], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 384, 154, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
